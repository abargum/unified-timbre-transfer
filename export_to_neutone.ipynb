{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d98a931-c02e-4d13-b4ca-b6c7895cd5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:library loading\n",
      "INFO:root:DEBUG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "  [INFO]: device is not None, use mps\n",
      "  [INFO]    > call by:torchfcpe.tools.spawn_infer_cf_naive_mel_pe_from_pt\n",
      "  [WARN] args.model.use_harmonic_emb is None; use default False\n",
      "  [WARN]    > call by:torchfcpe.tools.spawn_cf_naive_mel_pe\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logging.info(\"library loading\")\n",
    "logging.info(\"DEBUG\")\n",
    "\n",
    "import torch\n",
    "import librosa\n",
    "\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "import cached_conv as cc\n",
    "import gin\n",
    "import nn_tilde\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Union, Optional\n",
    "from absl import flags, app\n",
    "\n",
    "import sys, os\n",
    "try:\n",
    "    import raveish\n",
    "except:\n",
    "    import sys, os \n",
    "    sys.path.append(os.path.abspath('.'))\n",
    "    import raveish\n",
    "\n",
    "import raveish.core\n",
    "import raveish.dataset\n",
    "from raveish.transforms import get_augmentations, add_augmentation\n",
    "import raveish.blocks\n",
    "import raveish.resampler\n",
    "import IPython.display as ipd\n",
    "import pickle\n",
    "\n",
    "from raveish.cached_a_weight import Cached_A_Weight as cached_a_weight\n",
    "from raveish.pitch_enc import PitchEncoderV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad9e7918-19ba-420d-b9f0-5c33729b1219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:building UNIFIED_TT\n",
      "/Users/andersbargum/miniconda3/envs/unified/lib/python3.9/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n",
      "INFO:root:model found : pretrained/causal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading checkpoint: pretrained/causal/latest.ckpt\n"
     ]
    }
   ],
   "source": [
    "cc.use_cached_conv(True)\n",
    "\n",
    "run = \"pretrained/causal\"\n",
    "ema_weights = False\n",
    "prior_flag = False\n",
    "channel_flag = None\n",
    "sr_flag = 44100\n",
    "fidelity_flag =.95\n",
    "\n",
    "logging.info(\"building UNIFIED_TT\")\n",
    "\n",
    "gin.parse_config_file(os.path.join(run, \"config.gin\"))\n",
    "checkpoint = raveish.core.search_for_run(run)\n",
    "print(\"loading checkpoint:\", checkpoint)\n",
    "\n",
    "pretrained = raveish.UNIFIED_TT()\n",
    "if run is not None:\n",
    "    logging.info('model found : %s'%run)\n",
    "    checkpoint = torch.load(checkpoint, map_location='cpu')\n",
    "    if ema_weights and \"EMA\" in checkpoint[\"callbacks\"]:\n",
    "        pretrained.load_state_dict(\n",
    "            checkpoint[\"callbacks\"][\"EMA\"],\n",
    "            strict=False,\n",
    "        )\n",
    "    else:\n",
    "        pretrained.load_state_dict(\n",
    "            checkpoint[\"state_dict\"],\n",
    "            strict=False,\n",
    "        )\n",
    "else:\n",
    "    logging.error(\"No checkpoint found\")\n",
    "    exit()\n",
    "    \n",
    "pretrained.eval()\n",
    "\n",
    "pitch_enc = PitchEncoderV2(data_size=6,\n",
    "                           capacity=16,\n",
    "                           ratios=[4,4,4,2],\n",
    "                           latent_size=1440,\n",
    "                           n_out=1,\n",
    "                           kernel_size=3,\n",
    "                           dilations=[[1, 3, 9], [1, 3, 9], [1, 3, 9], [1, 3]])\n",
    "\n",
    "pitch_enc.load_state_dict(torch.load(f\"raveish/utils/caus2048_mb6.pth\", weights_only=True))\n",
    "pretrained.pitch_encoder = pitch_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c57bea-11ba-48ac-a962-5dc65c1e0edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(pretrained.decoder.net[2].cumulative_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25791ff7-2b87-4414-b6f9-5e6b534b6fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 131072])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andersbargum/miniconda3/envs/unified/lib/python3.9/site-packages/torch/functional.py:730: UserWarning: A window was not provided. A rectangular window will be applied,which is known to cause spectral leakage. Other windows such as torch.hann_window or torch.hamming_window are recommended to reduce spectral leakage.To suppress this warning and use a rectangular window, explicitly set `window=torch.ones(n_fft, device=<device>)`. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/SpectralOps.cpp:842.)\n",
      "  return _VF.stft(  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "for m in pretrained.modules():\n",
    "    if hasattr(m, \"weight_g\"):\n",
    "        nn.utils.remove_weight_norm(m)\n",
    "\n",
    "t = torch.rand(1, 1, 131072)\n",
    "out, _, _, _ = pretrained(t, ['Violin'])\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73ebb6b7-4d65-41f4-b492-74c12e582948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cello': {'mean': -1.0976669, 'std': 0.99742645, 'mean_f0': 150.07826, 'n_files': 11}, 'Violin': {'mean': -1.1541308, 'std': 0.95938534, 'mean_f0': 506.10043, 'n_files': 34}, 'Trombone': {'mean': -1.228859, 'std': 1.178475, 'mean_f0': 179.20522, 'n_files': 8}, 'Bassoon': {'mean': -1.0357323, 'std': 1.1757089, 'mean_f0': 200.41727, 'n_files': 3}, 'Clarinet': {'mean': -1.1593133, 'std': 1.1082362, 'mean_f0': 356.0085, 'n_files': 10}, 'Oboe': {'mean': -1.2284337, 'std': 0.859931, 'mean_f0': 533.29974, 'n_files': 6}, 'Trumpet': {'mean': -1.4467067, 'std': 1.2905153, 'mean_f0': 384.7168, 'n_files': 22}, 'Saxophone': {'mean': -1.29092, 'std': 1.3220173, 'mean_f0': 343.31354, 'n_files': 11}, 'Horn': {'mean': -1.367948, 'std': 1.3526137, 'mean_f0': 257.88876, 'n_files': 5}, 'Flute': {'mean': -1.1600183, 'std': 1.0587157, 'mean_f0': 631.1199, 'n_files': 18}}\n",
      "Mean of means: -1.2169728994369506\n",
      "Mean of stds: 1.1303024888038635\n"
     ]
    }
   ],
   "source": [
    "with open('raveish/utils/loudness_stats.pkl', 'rb') as file:\n",
    "    loudness_dict = pickle.load(file)\n",
    "\n",
    "print(loudness_dict)\n",
    "\n",
    "# Extract the mean and std values\n",
    "means = [v['mean'] for v in loudness_dict.values()]\n",
    "stds = [v['std'] for v in loudness_dict.values()]\n",
    "\n",
    "# Compute the averages\n",
    "global_mean = (sum(means) / len(means))\n",
    "global_std = sum(stds) / len(stds)\n",
    "\n",
    "print(\"Mean of means:\", global_mean)\n",
    "print(\"Mean of stds:\", global_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7cbf59b-3827-478a-a194-7329d9f39c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scripted(nn_tilde.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 pretrained: raveish.UNIFIED_TT,\n",
    "                 channels: Optional[int] = None,\n",
    "                 fidelity: float = .95,\n",
    "                 target_sr: bool = None) -> None:\n",
    "\n",
    "        super().__init__()\n",
    "        self.pqmf = pretrained.pqmf\n",
    "        self.sr = pretrained.sr\n",
    "        self.spectrogram = pretrained.spectrogram\n",
    "        self.resampler = None\n",
    "        self.input_mode = pretrained.input_mode\n",
    "        self.output_mode = pretrained.output_mode\n",
    "        self.n_channels = pretrained.n_channels\n",
    "        self.target_channels = channels or self.n_channels\n",
    "        self.stereo_mode = False\n",
    "\n",
    "        if target_sr is not None:\n",
    "            if target_sr != self.sr:\n",
    "                assert not target_sr % self.sr, \"Incompatible target sampling rate\"\n",
    "                self.resampler = raveish.resampler.Resampler(target_sr, self.sr)\n",
    "                self.sr = target_sr\n",
    "\n",
    "        self.full_latent_size = pretrained.latent_size\n",
    "\n",
    "        self.register_attribute(\"learn_target\", False)\n",
    "        self.register_attribute(\"reset_target\", False)\n",
    "        self.register_attribute(\"learn_source\", False)\n",
    "        self.register_attribute(\"reset_source\", False)\n",
    "\n",
    "        self.register_buffer(\"latent_pca\", pretrained.latent_pca)\n",
    "        self.register_buffer(\"latent_mean\", pretrained.latent_mean)\n",
    "        self.register_buffer(\"fidelity\", pretrained.fidelity)\n",
    "\n",
    "        self.register_buffer(\"global_mean\", torch.tensor(global_mean))\n",
    "        self.register_buffer(\"global_std\", torch.tensor(global_std))\n",
    "\n",
    "        self.latent_size = 2\n",
    "\n",
    "        # have to init cached conv before graphing\n",
    "        self.decoder = pretrained.decoder\n",
    "        self.amp_block = pretrained.amp_block\n",
    "        self.pitch_encoder = pretrained.pitch_encoder\n",
    "        \n",
    "        x_len = 2**14\n",
    "        x = torch.zeros(1, self.n_channels, x_len)\n",
    "        \n",
    "        # configure encoder\n",
    "        if (pretrained.input_mode == \"pqmf\") or (pretrained.output_mode == \"pqmf\"):\n",
    "            # scripting fails if cached conv is not initialized\n",
    "            self.pqmf(torch.zeros(1, 1, x_len))\n",
    "\n",
    "        encode_shape = (pretrained.n_channels, 2**14) \n",
    "\n",
    "        self.register_method(\n",
    "            \"forward\",\n",
    "            in_channels=1,\n",
    "            in_ratio=1,\n",
    "            out_channels=self.target_channels,\n",
    "            out_ratio=1,\n",
    "            input_labels=['(signal) Channel %d'%d for d in range(1, 1 + 1)],\n",
    "            output_labels=['(signal) Channel %d'%d for d in range(1, self.target_channels+1)],\n",
    "            test_method=False\n",
    "        )\n",
    "\n",
    "    def post_process_latent(self, z):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def pre_process_latent(self, z):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def update_adain(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, raveish.blocks.AdaptiveInstanceNormalization):\n",
    "                m.learn_x.zero_()\n",
    "                m.learn_y.zero_()\n",
    "\n",
    "                if self.learn_target[0]:\n",
    "                    m.learn_y.add_(1)\n",
    "                if self.learn_source[0]:\n",
    "                    m.learn_x.add_(1)\n",
    "\n",
    "                if self.reset_target[0]:\n",
    "                    m.reset_y()\n",
    "                if self.reset_source[0]:\n",
    "                    m.reset_x()\n",
    "\n",
    "        self.reset_source = False,\n",
    "        self.reset_target = False,\n",
    "\n",
    "    @torch.jit.export\n",
    "    def set_stereo_mode(self, stereo):\n",
    "        self.stereo_mode = bool(stereo)\n",
    "\n",
    "\n",
    "    @torch.jit.export\n",
    "    def forward(self, x, emb_x, emb_y, p_mult, n_mult, loudness, loudness_linear):\n",
    "        batch_size = x.shape[:-2]\n",
    "\n",
    "        x_m = self.pqmf(x)\n",
    "        x_m = x_m.reshape(batch_size + (-1, x_m.shape[-1]))\n",
    "        \n",
    "        pitch_logits = self.pitch_encoder(x_m[:, :6, :])\n",
    "        pitch = torch.argmax(pitch_logits, dim=1)\n",
    "        pitch = raveish.core.bins_to_frequency(pitch).unsqueeze(-1)\n",
    "        periodicity = raveish.core.entropy(pitch_logits)\n",
    "\n",
    "        pitch = pitch * p_mult\n",
    "\n",
    "        emb = torch.zeros(1, 2)\n",
    "        emb[:, 0] = emb_x\n",
    "        emb[:, 1] = emb_y\n",
    "\n",
    "        emb = emb.unsqueeze(-1)\n",
    "        amplitudes = self.amp_block(emb.transpose(2, 1))\n",
    "        emb = emb.repeat(1, 1, periodicity.shape[-1])\n",
    "\n",
    "        y, _, _, = self.decoder(emb,\n",
    "                                pitch, \n",
    "                                amplitudes,\n",
    "                                loudness.transpose(2,1),\n",
    "                                loudness_linear.unsqueeze(-1),\n",
    "                                periodicity.unsqueeze(-1))\n",
    "\n",
    "        batch_size = emb.shape[:-2]\n",
    "        if self.pqmf is not None:\n",
    "            y = y.reshape(y.shape[0] * self.n_channels, -1, y.shape[-1])\n",
    "            y = self.pqmf.inverse(y)\n",
    "            y = y.reshape(batch_size+(self.n_channels, -1))\n",
    "\n",
    "        if self.resampler is not None:\n",
    "            y = self.resampler.from_model_sampling_rate(y)\n",
    "                \n",
    "        return y\n",
    "\n",
    "    @torch.jit.export\n",
    "    def get_learn_target(self) -> bool:\n",
    "        return self.learn_target[0]\n",
    "\n",
    "    @torch.jit.export\n",
    "    def set_learn_target(self, learn_target: bool) -> int:\n",
    "        self.learn_target = (learn_target, )\n",
    "        return 0\n",
    "\n",
    "    @torch.jit.export\n",
    "    def get_learn_source(self) -> bool:\n",
    "        return self.learn_source[0]\n",
    "\n",
    "    @torch.jit.export\n",
    "    def set_learn_source(self, learn_source: bool) -> int:\n",
    "        self.learn_source = (learn_source, )\n",
    "        return 0\n",
    "\n",
    "    @torch.jit.export\n",
    "    def get_reset_target(self) -> bool:\n",
    "        return self.reset_target[0]\n",
    "\n",
    "    @torch.jit.export\n",
    "    def set_reset_target(self, reset_target: bool) -> int:\n",
    "        self.reset_target = (reset_target, )\n",
    "        return 0\n",
    "\n",
    "    @torch.jit.export\n",
    "    def get_reset_source(self) -> bool:\n",
    "        return self.reset_source[0]\n",
    "\n",
    "    @torch.jit.export\n",
    "    def set_reset_source(self, reset_source: bool) -> int:\n",
    "        self.reset_source = (reset_source, )\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29e766ff-177a-408d-a607-057c176b4ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_class = Scripted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cb43d77-e189-45e1-832a-98dae9124996",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:script model\n",
      "INFO:root:Registering method \"forward\"\n",
      "WARNING:root:Added method \"forward\" without testing it.\n"
     ]
    }
   ],
   "source": [
    "prior_scripted=None\n",
    "\n",
    "logging.info(\"script model\")\n",
    "scripted = script_class(\n",
    "    pretrained=pretrained,\n",
    "    channels = channel_flag,\n",
    "    fidelity=fidelity_flag,\n",
    "    target_sr=sr_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57c09e16-6ca5-4800-8026-bde5983c7ebc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:save model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2048])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:this model will not work with the RAVE VST. \n",
      " Caught error : name 'z' is not defined\n",
      "INFO:root:all good ! model exported to /Users/andersbargum/Documents/unified-timbre-transfer/pretrained/causal_streaming.ts\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(1, pretrained.n_channels, 2**14)\n",
    "x = torch.zeros(1, 1, 2048)\n",
    "\n",
    "emb_x = torch.zeros(1)\n",
    "emb_y = torch.zeros(1)\n",
    "mult = torch.ones(1)\n",
    "l = torch.ones(1, 1, 1)\n",
    "ln = torch.ones(1, 1)\n",
    "\n",
    "y = scripted.forward(x, emb_x, emb_y, mult, mult, l, ln)\n",
    "print(y.shape)\n",
    "\n",
    "logging.info(\"save model\")\n",
    "output = os.path.dirname(run)\n",
    "model_name = run.split(os.sep)[-1]\n",
    "\n",
    "model_name += \"_streaming.ts\"\n",
    "\n",
    "output = os.path.abspath(output)\n",
    "if not os.path.isdir(output):\n",
    "    os.makedirs(output)\n",
    "scripted.export_to_ts(os.path.join(output, model_name))\n",
    "try:\n",
    "    if pretrained.n_channels <= 2:\n",
    "        # test stereo mode for VST export\n",
    "        scripted.set_stereo_mode(True)\n",
    "        z_vst_input = torch.zeros(2, scripted.full_latent_size, z.shape[-1])\n",
    "        out = scripted.decode(z_vst_input)\n",
    "        assert out.shape[1] == 2, \"model output is not stereo\"\n",
    "        logging.info(f\"this model seems compatible with the RAVE vst.\")\n",
    "except Exception as e:\n",
    "    logging.warning(f\"this model will not work with the RAVE VST. \\n Caught error : %s\"%e)\n",
    "\n",
    "logging.info(f\"all good ! model exported to {os.path.join(output, model_name)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
