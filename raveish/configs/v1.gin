from __gin__ import dynamic_registration

import raveish
from raveish import pqmf
from raveish import core
from raveish import blocks
from raveish import discriminator
from raveish import dataset

import cached_conv as cc
import torch

SAMPLING_RATE = 44100
CAPACITY = 64
N_BAND = 16
LATENT_SIZE = 32
RATIOS = [4, 4, 4, 2]
PHASE_1_DURATION = 700000

# CORE CONFIGURATION
core.AudioDistanceV1:
    multiscale_stft = @core.MultiScaleSTFT
    log_epsilon = 1e-7

core.MultiScaleSTFT:
    scales = [2048, 1024, 512, 256, 128]
    sample_rate = %SAMPLING_RATE
    magnitude = True

dataset.split_dataset.max_residual = 1000

# CONVOLUTION CONFIGURATION
cc.Conv1d.bias = True
cc.ConvTranspose1d.bias = True

# PQMF
pqmf.CachedPQMF:
    attenuation = 100
    n_band = %N_BAND

blocks.normalization.mode = 'weight_norm'


# DISCRIMINATOR
discriminator.ConvNet:
    in_size = 1
    out_size = 1
    capacity = %CAPACITY
    n_layers = 4
    stride = 4

scales/discriminator.ConvNet:
    conv = @torch.nn.Conv1d
    kernel_size = 15

discriminator.MultiScaleDiscriminator:
    n_discriminators = 3
    convnet = @scales/discriminator.ConvNet

feature_matching/core.mean_difference:
    norm = 'L1'

# MODEL ASSEMBLING
raveish.UNIFIED_TT:
    latent_size = %LATENT_SIZE
    pqmf = @pqmf.CachedPQMF
    sampling_rate = %SAMPLING_RATE
    discriminator = @discriminator.MultiScaleDiscriminator
    phase_1_duration = %PHASE_1_DURATION
    gan_loss = @core.hinge_gan
    valid_signal_crop = False
    feature_matching_fun = @feature_matching/core.mean_difference
    num_skipped_features = 0
    audio_distance = @core.AudioDistanceV1
    multiband_audio_distance = @core.AudioDistanceV1
    weights = {
        'feature_matching': 10
        }

raveish.BetaWarmupCallback:
    initial_value = .1
    target_value = .1
    warmup_len = 1
